{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラムの構成\n",
    "#1.事前設定:oandapyのインストール, googlecolabのドライブマウント, setup_fxconn()\n",
    "#2.為替相場から値を取得:fetch_fxvalue()\n",
    "#3.データ成形し、特徴量抽出:calc_feat()\n",
    "#4.モデル学習:build_model()\n",
    "#5.将来の為替変動予測:predict()\n",
    "#6.予測結果をもとに取引の戦略を立てる:build_strategy()\n",
    "#7.取引:transaction_with_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/oanda/oandapy.git\n",
      "  Cloning https://github.com/oanda/oandapy.git to c:\\users\\satoshi\\appdata\\local\\temp\\pip-req-build-kx_ol5_e\n",
      "Requirement already satisfied (use --upgrade to upgrade): oandapy==0.1 from git+https://github.com/oanda/oandapy.git in c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\n",
      "Requirement already satisfied: requests in c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from oandapy==0.1) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->oandapy==0.1) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->oandapy==0.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->oandapy==0.1) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests->oandapy==0.1) (2.8)\n",
      "Building wheels for collected packages: oandapy\n",
      "  Running setup.py bdist_wheel for oandapy: started\n",
      "  Running setup.py bdist_wheel for oandapy: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\satoshi\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-cerlsp6k\\wheels\\84\\33\\ea\\2d5dddc641a73a23c531dd327e6e743ccbad487a2ae6f38c30\n",
      "Successfully built oandapy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#1.事前設定\n",
    "#oandapyインストール\n",
    "! pip install git+https://github.com/oanda/oandapy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google collaboration上で、Google ドライブをマウント\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 為替相場から値を取得:fetch_fxvalue()\n",
    "# API接続設定のファイルを読み込む\n",
    "import configparser\n",
    "import oandapy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#TODO: 外部から読み込む形にしたい\n",
    "#path_oanda='./drive/My Drive/oandapy' #google colac用\n",
    "path_oanda='..'\n",
    "path_config=path_oanda+'/data/config.txt'\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(path_config)\n",
    "\n",
    "#TODO: グローバル変数にしたくない\n",
    "instrument = config['oanda']['instrument']\n",
    "granularity = config['oanda']['granularity']\n",
    "count = int(config['oanda']['count'])\n",
    "api_key = config['oanda']['api_key']\n",
    "account_id = config['oanda']['account_id']\n",
    "\n",
    "\n",
    "def create_api_fxconn(path_config):\n",
    "# API接続\n",
    "    oanda = oandapy.API(environment=\"practice\", access_token=api_key)\n",
    "    return oanda\n",
    "\n",
    "\n",
    "def iso_jp(iso):\n",
    "#日付の調整する\n",
    "#文字列 -> datetime\n",
    "     date = None\n",
    "     try:\n",
    "         date = datetime.strptime(iso, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "         date = pytz.utc.localize(date).astimezone(pytz.timezone(\"Asia/Tokyo\"))\n",
    "     except ValueError:\n",
    "         try:\n",
    "             date = datetime.strptime(iso, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "             date = dt.astimezone(pytz.timezone(\"Asia/Tokyo\"))\n",
    "         except ValueError:\n",
    "             pass\n",
    "     return date\n",
    "\n",
    "  \n",
    "def create_df_fxvalue_latesthistory_rawdata(oanda):\n",
    "#生データのdfを生成\n",
    "    instrument, granularity, count = (config['oanda']['instrument'], \n",
    "                                      config['oanda']['granularity'], \n",
    "                                      int(config['oanda']['count']))\n",
    "    json_response = oanda.get_history(instrument=instrument, \n",
    "                                      granularity=granularity, \n",
    "                                      count=count)\n",
    "    df_response = pd.DataFrame(json_response[\"candles\"])\n",
    "    df_response[\"time\"] = df_response[\"time\"].apply(lambda x: iso_jp(x))\n",
    "    return df_response\n",
    "\n",
    "#-----------------main-----------------------------\n",
    "\n",
    "def fetch_fxvalue(path_config):\n",
    "#2のメイン関数, 為替の値を取得\n",
    "    instrument, granularity, count = (config['oanda']['instrument'], \n",
    "                                      config['oanda']['granularity'], \n",
    "                                      int(config['oanda']['count']))\n",
    "    oanda = create_api_fxconn(path_config=path_config)\n",
    "    df_fxvalue_latesthistory_rawdata = create_df_fxvalue_latesthistory_rawdata(oanda)\n",
    "    return df_fxvalue_latesthistory_rawdata \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closeAsk</th>\n",
       "      <th>closeBid</th>\n",
       "      <th>complete</th>\n",
       "      <th>highAsk</th>\n",
       "      <th>highBid</th>\n",
       "      <th>lowAsk</th>\n",
       "      <th>lowBid</th>\n",
       "      <th>openAsk</th>\n",
       "      <th>openBid</th>\n",
       "      <th>time</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.808</td>\n",
       "      <td>109.795</td>\n",
       "      <td>True</td>\n",
       "      <td>109.823</td>\n",
       "      <td>109.812</td>\n",
       "      <td>109.808</td>\n",
       "      <td>109.795</td>\n",
       "      <td>109.820</td>\n",
       "      <td>109.808</td>\n",
       "      <td>2020-02-06 00:07:00+09:00</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109.794</td>\n",
       "      <td>109.782</td>\n",
       "      <td>True</td>\n",
       "      <td>109.809</td>\n",
       "      <td>109.796</td>\n",
       "      <td>109.788</td>\n",
       "      <td>109.775</td>\n",
       "      <td>109.809</td>\n",
       "      <td>109.796</td>\n",
       "      <td>2020-02-06 00:08:00+09:00</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.808</td>\n",
       "      <td>109.796</td>\n",
       "      <td>True</td>\n",
       "      <td>109.808</td>\n",
       "      <td>109.796</td>\n",
       "      <td>109.794</td>\n",
       "      <td>109.782</td>\n",
       "      <td>109.795</td>\n",
       "      <td>109.783</td>\n",
       "      <td>2020-02-06 00:09:00+09:00</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.826</td>\n",
       "      <td>109.814</td>\n",
       "      <td>True</td>\n",
       "      <td>109.827</td>\n",
       "      <td>109.815</td>\n",
       "      <td>109.797</td>\n",
       "      <td>109.783</td>\n",
       "      <td>109.810</td>\n",
       "      <td>109.797</td>\n",
       "      <td>2020-02-06 00:10:00+09:00</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.824</td>\n",
       "      <td>109.813</td>\n",
       "      <td>True</td>\n",
       "      <td>109.839</td>\n",
       "      <td>109.828</td>\n",
       "      <td>109.822</td>\n",
       "      <td>109.809</td>\n",
       "      <td>109.828</td>\n",
       "      <td>109.815</td>\n",
       "      <td>2020-02-06 00:11:00+09:00</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   closeAsk  closeBid  complete  highAsk  highBid   lowAsk   lowBid  openAsk  \\\n",
       "0   109.808   109.795      True  109.823  109.812  109.808  109.795  109.820   \n",
       "1   109.794   109.782      True  109.809  109.796  109.788  109.775  109.809   \n",
       "2   109.808   109.796      True  109.808  109.796  109.794  109.782  109.795   \n",
       "3   109.826   109.814      True  109.827  109.815  109.797  109.783  109.810   \n",
       "4   109.824   109.813      True  109.839  109.828  109.822  109.809  109.828   \n",
       "\n",
       "   openBid                      time  volume  \n",
       "0  109.808 2020-02-06 00:07:00+09:00      77  \n",
       "1  109.796 2020-02-06 00:08:00+09:00     128  \n",
       "2  109.783 2020-02-06 00:09:00+09:00      78  \n",
       "3  109.797 2020-02-06 00:10:00+09:00     118  \n",
       "4  109.815 2020-02-06 00:11:00+09:00      81  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 テスト\n",
    "path_oanda='..'\n",
    "path_config=path_oanda+'/data/config.txt'\n",
    "tmp = fetch_fxvalue(path_config)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 特徴量抽出:feat_calc()\n",
    "# API接続設定のファイルを読み込む\n",
    "\n",
    "def data_maker(data, window_len):\n",
    "    data_lstm_in=[]\n",
    "    if len(data)==window_len:\n",
    "        temp = data[:window_len].copy()\n",
    "        temp = temp / temp.iloc[0] - 1\n",
    "        data_lstm_in.append(temp)\n",
    "    for i in range(len(data) - window_len):\n",
    "        temp = data[i:(i + window_len)].copy()\n",
    "        temp = temp / temp.iloc[0] - 1\n",
    "        data_lstm_in.append(temp)\n",
    "    return data_lstm_in\n",
    "\n",
    "\n",
    "def pd_to_np(data_lstm_in):\n",
    "#うんこみたいな関数すぎる、変えたい\n",
    "#もともとdf？listになってるんやけど\n",
    "    data_lstm_in = [np.array(data_lstm_input) for data_lstm_input in data_lstm_in]  #array のリスト\n",
    "    data_lstm_in = np.array(data_lstm_in) #np.array\n",
    "    return data_lstm_in\n",
    "\n",
    "\n",
    "def extract_feature(df_rawdata, ratio_num_traindata):\n",
    "#特徴量抽出->ここをいじります\n",
    "#ratio_num_traindataは訓練データと検証用データの分割比\n",
    "#TODO: ratio_num_traindataは引数で与えたい\n",
    "\n",
    "    #1. 特徴量算出に必要なカラムを設定\n",
    "    df = df_rawdata[['time', 'openAsk']]\n",
    "    df.columns = ['time', 'open']\n",
    "\n",
    "    #2. 予測に使うデータ数を設定\n",
    "    window_len = 10\n",
    "    #3. 訓練データと検証用データを所定の割合で分割\n",
    "    #TODO: ごちゃごちゃしているので、書き換えたい\n",
    "    train, test = df[df.index < int(len(df)*ratio_num_traindata)], \\\n",
    "                    df[df.index >= int(len(df)*ratio_num_traindata)]\n",
    "    latest = test[:window_len]\n",
    "    del train['time']\n",
    "    del test['time']\n",
    "    del latest['time']\n",
    "    length = len(test)- window_len\n",
    "    \n",
    "    #モデル入力、モデル出力用にデータ成形\n",
    "    ##ここを直して、特徴量抽出のアルゴリズム考える\n",
    "    #TODO: data_makerとかpd_to_npとかいう意味わからん関数書き換えたい\n",
    "    #TODO: latestがよくわからん\n",
    "    train_lstm_in = data_maker(train, window_len)\n",
    "    lstm_train_out = (train['open'][window_len:].values / train['open'][:-window_len].values)-1\n",
    "    test_lstm_in = data_maker(test, window_len)\n",
    "    lstm_test_out = (test['open'][window_len:].values / test['open'][:-window_len].values)-1\n",
    "    latest_lstm_in = data_maker(latest, window_len)\n",
    "    train_lstm_in = pd_to_np(train_lstm_in)\n",
    "    test_lstm_in = pd_to_np(test_lstm_in)\n",
    "    latest_lstm_in = pd_to_np(latest_lstm_in)\n",
    "    \n",
    "    #入出力の名前とかが意味わからなかったので、dictで管理してる\n",
    "    X_dict = {'train':train_lstm_in, 'test':test_lstm_in, 'latest':latest_lstm_in}\n",
    "    y_dict = {'train':lstm_train_out, 'test':lstm_test_out}\n",
    "\n",
    "    return X_dict, y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3テスト\n",
    "X_dict, y_dict = extract_feature(tmp, ratio_num_traindata=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0126 14:28:15.028591 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0126 14:28:16.147869 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0126 14:28:16.441787 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0126 14:28:17.533325 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0126 14:28:17.562794 18344 deprecation.py:506] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0126 14:28:17.641747 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0126 14:28:18.690308 18344 deprecation.py:323] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0126 14:28:20.294610 18344 deprecation_wrapper.py:119] From c:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4045c1bc50d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#TODO ネットワークの設定を、別途configファイルかargs.parserで引数として外部設定できるようにする\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneurons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# #未来の値\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\satoshi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#4 モデル学習: train_model()\n",
    "\n",
    "#TODO importはutil.pyにまとめる\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense,Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "np.random.seed(202)\n",
    "\n",
    "\n",
    "#モデルのハイパーパラメータ設定\n",
    "#TODO もっとすっきり書きたい→csvとかに書いておいて、pd.read_csv()とするといい？\n",
    "def set_model_param_dict():\n",
    "    param_dict = dict()\n",
    "    param_dict['activation']=\"relu\"\n",
    "    param_dict['dropout']=0.25\n",
    "    param_dict['loss']=\"mae\"\n",
    "    param_dict['optimizer']=\"adam\"\n",
    "    param_dict['num_LSTMcells']=248\n",
    "    param_dict['recurrent_dropout']=0.3\n",
    "\n",
    "    param_dict['num_units_Dense1']=64\n",
    "    param_dict['num_units_Dense2']=32\n",
    "\n",
    "    param_dict['epochs']=10\n",
    "    param_dict['batch_size']=1\n",
    "    param_dict['flag_shuffle_traindata']=True\n",
    "\n",
    "    return param_dict\n",
    "\n",
    "#出力データのサイズ抽出\n",
    "def extract_output_size(output_arr):\n",
    "    if output_arr.ndim == 1:\n",
    "      output_size = 1\n",
    "    else: \n",
    "      output_size = output_arr.shape[1]\n",
    "    \n",
    "    return output_size\n",
    "\n",
    "#===========================================================\n",
    "#モデルの定義\n",
    "def define_model(X, y, param_dict):\n",
    "    #TODO 変数名と同じ要素を取ってくるようにしたい：assign_param(model_params, given_params)\n",
    "    #クラスとかをつかうとよい？\n",
    "    #最も理想param_list=param_dict**からのnum_cellとかに値代入されている\n",
    "    #ネットワーク構造を決定するパラメタ群は別の変数にしたい\n",
    "    activation = param_dict['activation']\n",
    "    dropout = param_dict['dropout']\n",
    "    loss = param_dict['loss']\n",
    "    optimizer = param_dict['optimizer']\n",
    "    num_LSTMcells = param_dict['num_LSTMcells']\n",
    "    recurrent_dropout = param_dict['recurrent_dropout']\n",
    "    \n",
    "    #shape[0]は特徴量ベクトルの数\n",
    "    #shape[1]は時間方向のデータ数\n",
    "    #shape[2]は他のなにか\n",
    "    input_shape = (X.shape[1], X.shape[2])\n",
    "\n",
    "    num_units_Dense1 = param_dict['num_units_Dense1']\n",
    "    num_units_Dense2 = param_dict['num_units_Dense2']\n",
    "    num_dim_output = extract_output_size(y)\n",
    "    #TODO 上記全部２つの関数にまとめたい：set_hyperparamer, extract_output_size\n",
    "\n",
    "\n",
    "    #モデルの定義\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(num_LSTMcells, dropout=dropout,recurrent_dropout=recurrent_dropout,input_shape=input_shape)))\n",
    "    model.add(Dense(num_units_Dense1,activation=activation))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_units_Dense2,activation=activation))\n",
    "    model.add(Dense(num_dim_output))\n",
    " \n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "#モデル学習(一応historyも返すようにしている)\n",
    "def train_model_with_history(defined_model, X_train, y_train, param_dict):\n",
    "    epochs = param_dict['epochs']\n",
    "    batch_size = param_dict['batch_size']\n",
    "    flag_shuffle_traindata = param_dict['flag_shuffle_traindata'] \n",
    "    \n",
    "    history = defined_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=flag_shuffle_traindata)\n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "#メイン：モデルを定義、学習を行いファイルを生成\n",
    "def build_model(X_train, y_train, param_dict):\n",
    "    defined_model = define_model(X=X_train, y=y_train, param_dict=param_dict)\n",
    "    model, history = train_model_with_history(defined_model=defined_model, X_train=X_train, y_train=y_train, param_dict=param_dict)\n",
    "    return model #arbitrarily add -> history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 テスト\n",
    "X_train, y_train = X_dict['train'], y_dict['train']\n",
    "param_dict = set_model_param_dict()\n",
    "model = build_model(X_train, y_train, param_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
